{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6d9bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##DAY-1 /EDA, Scaling....\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df= pd.read_csv('creditcard.csv')\n",
    "#df['Class'].value_counts()\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "#sb.countplot(x='Class',data=df)\n",
    "#plt.title('fraud vs legit')\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# v_features = ['V1', 'V2', 'V3']\n",
    "\n",
    "# plt.figure(figsize=(12, 6))\n",
    "\n",
    "# for i, v in enumerate(v_features):\n",
    "#     plt.subplot(1, 3, i+1)                 # 1 row, 3 cols, i-th plot\n",
    "#     sns.histplot(df[v], bins=50, kde=True)\n",
    "#     plt.title(f'Distribution of {v}')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "df_scaled=df.copy()\n",
    "scaler=StandardScaler()\n",
    "df_scaled[['Amount','Time']]= scaler.fit_transform(df[['Amount','Time']])\n",
    "\n",
    "df_scaled[['Amount','Time']].describe()\n",
    "\n",
    "X = df_scaled.drop('Class', axis=1)\n",
    "y = df_scaled['Class']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# print(X_train.shape)\n",
    "# print(X_test.shape)\n",
    "# print(df.shape)\n",
    "corr = df.corr()\n",
    "plt.figure(figsize=(12,8))\n",
    "sb.heatmap(corr, cmap='coolwarm',annot=False)\n",
    "plt.title('correlation heatmap')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c32d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Day-2/UNI-variate anomaly det\n",
    "features = ['V17', 'V14', 'V12']\n",
    "X_uni = X_train[features]\n",
    "# print(X_uni.shape)\n",
    "def estimate_gaussian(X):\n",
    "    mu = X.mean(axis=0)\n",
    "    sigma2 = X.var(axis=0)\n",
    "    return mu, sigma2\n",
    "\n",
    "mu, sigma2 = estimate_gaussian(X_uni)\n",
    "#\n",
    "from scipy.stats import norm\n",
    "\n",
    "def calculate_probability(X, mu, sigma2):\n",
    "    p = 1\n",
    "    for i in range(len(mu)):\n",
    "        p_i = norm.pdf(X.iloc[:, i], loc=mu.iloc[i], scale=np.sqrt(sigma2.iloc[i]))\n",
    "        p *= p_i \n",
    "    return p\n",
    "\n",
    "p_train = calculate_probability(X_uni, mu, sigma2)\n",
    "#\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "def select_threshold(y_val, p_val):\n",
    "    best_epsilon = 0\n",
    "    best_f1 = 0\n",
    "    epsilons = np.linspace(min(p_val), max(p_val), 1000)\n",
    "\n",
    "    for epsilon in epsilons:\n",
    "        preds = (p_val < epsilon).astype(int)\n",
    "        f1 = f1_score(y_val, preds)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_epsilon = epsilon\n",
    "\n",
    "    return best_epsilon, best_f1\n",
    "\n",
    "X_val_uni = X_test[features]\n",
    "p_val = calculate_probability(X_val_uni, mu, sigma2)\n",
    "\n",
    "epsilon, best_f1 = select_threshold(y_test, p_val)\n",
    "#\n",
    "y_pred_uni = (p_val < epsilon).astype(int)\n",
    "\n",
    "precision = precision_score(y_test, y_pred_uni)\n",
    "recall = recall_score(y_test, y_pred_uni)\n",
    "f1 = f1_score(y_test, y_pred_uni)\n",
    "\n",
    "print(f\"Univariate Gaussian → Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2eb890",
   "metadata": {},
   "outputs": [],
   "source": [
    "##DAY-2/ Multi-variate Anomaly det\n",
    "features = ['V14', 'V12', 'V10', 'V17', 'V16', 'V3', 'V7', 'V11', 'V18']\n",
    "X_m = X_train[features]\n",
    "X_val_m = X_test[features]\n",
    "#\n",
    "def estimate_gaussian_multi(X):\n",
    "    mu = X.mean(axis=0)\n",
    "    sigma = np.cov(X.T)  \n",
    "    return mu, sigma\n",
    "\n",
    "mu_m, sigma_m = estimate_gaussian_multi(X_m)\n",
    "#\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "def calculate_multivariate_prob(X, mu, sigma):\n",
    "    dist = multivariate_normal(mean=mu, cov=sigma)\n",
    "    return dist.pdf(X)\n",
    "\n",
    "p_val_m = calculate_multivariate_prob(X_val_m, mu_m, sigma_m)\n",
    "#\n",
    "epsilon_m, best_f1_m = select_threshold(y_test, p_val_m)\n",
    "#\n",
    "y_pred_m = (p_val_m < epsilon_m).astype(int)\n",
    "\n",
    "precision_m = precision_score(y_test, y_pred_m)\n",
    "recall_m = recall_score(y_test, y_pred_m)\n",
    "f1_m = f1_score(y_test, y_pred_m)\n",
    "\n",
    "print(f\"Multivariate Gaussian → Precision: {precision_m:.4f}, Recall: {recall_m:.4f}, F1: {f1_m:.4f}\")\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2c1e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##DAY-3 / PCA & LogREG\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "#\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_pca, X_test_pca, y_train_lr, y_test_lr = train_test_split(\n",
    "    X_pca, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "#\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(class_weight='balanced',random_state=42)\n",
    "lr.fit(X_train_pca, y_train_lr)\n",
    "#\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score\n",
    "\n",
    "y_pred_lr = lr.predict(X_test_pca)\n",
    "print(classification_report(y_test_lr, y_pred_lr, digits=4))\n",
    "# #\n",
    "# from sklearn.metrics import precision_recall_curve\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# y_scores = lr.predict_proba(X_test_pca)[:,1] \n",
    "# y_pred_custom = (y_scores > 0.0001).astype(int)\n",
    "\n",
    "# precision, recall, thresholds = precision_recall_curve(y_test, y_scores)\n",
    "\n",
    "# plt.plot(recall, precision)\n",
    "# plt.title(\"Precision-Recall Curve - Logistic Regression (PCA)\")\n",
    "# plt.xlabel(\"Recall\")\n",
    "# plt.ylabel(\"Precision\")\n",
    "# plt.grid()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d348f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Hybrid + evaluation framework\n",
    "\n",
    "y_hybrid = ((y_pred_uni == 1) | (y_pred_m == 1) | (y_pred_lr == 1)).astype(int)\n",
    "#\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "def evaluate_model(y_true, y_pred, model_name=\"Model\"):\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    print(f\"\\n {model_name}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "#\n",
    "evaluate_model(y_test, y_pred_uni, \"Univariate Gaussian\")\n",
    "evaluate_model(y_test, y_pred_m, \"Multivariate Gaussian\")\n",
    "evaluate_model(y_test, y_pred_lr, \"Logistic Regression (PCA)\")\n",
    "evaluate_model(y_test, y_hybrid, \"Hybrid Model (OR Vote)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb768e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Summary cell\n",
    "\n",
    "summary = []\n",
    "\n",
    "# Univariate\n",
    "summary.append([\n",
    "    \"Univariate Gaussian\",\n",
    "    precision_score(y_test, y_pred_uni),\n",
    "    recall_score(y_test, y_pred_uni),\n",
    "    f1_score(y_test, y_pred_uni)\n",
    "])\n",
    "\n",
    "# Multivariate\n",
    "summary.append([\n",
    "    \"Multivariate Gaussian\",\n",
    "    precision_score(y_test, y_pred_m),\n",
    "    recall_score(y_test, y_pred_m),\n",
    "    f1_score(y_test, y_pred_m)\n",
    "])\n",
    "\n",
    "# Logistic Regression\n",
    "summary.append([\n",
    "    \"Logistic Regression\",\n",
    "    precision_score(y_test, y_pred_lr),\n",
    "    recall_score(y_test, y_pred_lr),\n",
    "    f1_score(y_test, y_pred_lr)\n",
    "])\n",
    "\n",
    "# Hybrid Model\n",
    "summary.append([\n",
    "    \"Hybrid Model\",\n",
    "    precision_score(y_test, y_hybrid),\n",
    "    recall_score(y_test, y_hybrid),\n",
    "    f1_score(y_test, y_hybrid)\n",
    "])\n",
    "\n",
    "df_summary = pd.DataFrame(summary, columns=[\"Model\", \"Precision\", \"Recall\", \"F1\"])\n",
    "df_summary = df_summary.round(4)\n",
    "\n",
    "print(df_summary)\n",
    "\n",
    "# Export to markdown (for README)\n",
    "print(\"\\nMarkdown Table:\\n\")\n",
    "print(df_summary.to_markdown(index=False, tablefmt=\"github\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c18463",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
